{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "toxic-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ase.io\n",
    "import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from code_pytorch import *\n",
    "from utilities import *\n",
    "from miscellaneous import ClebschGordan\n",
    "torch.set_default_dtype(torch.float64)\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "torch.set_num_threads(1)\n",
    "from rascal.representations import SphericalInvariants\n",
    "from rascal.models import Kernel, train_gap_model\n",
    "from rascal.utils import FPSFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "valued-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "HARTREE_TO_EV = 27.211386245988\n",
    "FORCE_FACTOR = 51.42208619083232\n",
    "LAMBDA_MAX = 5\n",
    "HYPERS = {\n",
    "    'interaction_cutoff': 6.3,\n",
    "    'max_radial': 10,\n",
    "    'max_angular': LAMBDA_MAX,\n",
    "    'gaussian_sigma_type': 'Constant',\n",
    "    'gaussian_sigma_constant': 0.05,\n",
    "    'cutoff_smooth_width': 0.3,\n",
    "    'radial_basis': 'GTO',\n",
    "}\n",
    "\n",
    "train_subset = '0:20000'\n",
    "test_subset = '20000:21000'\n",
    "\n",
    "METHANE_PATH = '../methane.extxyz'\n",
    "clebsch = ClebschGordan(LAMBDA_MAX)\n",
    "N_MEASUREMENTS = 5\n",
    "GRID = [10, 25, 50, 100, 250, 500, 1000, 2500, 5000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "realistic-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_structures =  process_structures(ase.io.read(METHANE_PATH , index=train_subset))\n",
    "test_structures =  process_structures(ase.io.read(METHANE_PATH , index=test_subset))\n",
    "\n",
    "all_species = get_all_species(train_structures + test_structures)\n",
    "\n",
    "train_coefficients = get_coefs(train_structures, HYPERS, all_species) \n",
    "test_coefficients = get_coefs(test_structures, HYPERS, all_species) \n",
    "L2_mean = get_L2_mean(train_coefficients)\n",
    "\n",
    "for key in train_coefficients.keys():\n",
    "    train_coefficients[key] /= torch.sqrt(L2_mean)\n",
    "    test_coefficients[key] /= torch.sqrt(L2_mean)\n",
    "\n",
    "train_energies = [structure.info['energy'] for structure in train_structures]\n",
    "train_energies = np.array(train_energies) * HARTREE_TO_EV\n",
    "\n",
    "test_energies = [structure.info['energy'] for structure in test_structures]\n",
    "test_energies = np.array(test_energies) * HARTREE_TO_EV\n",
    "\n",
    "mean_e = np.mean(train_energies)\n",
    "train_energies = train_energies - mean_e\n",
    "test_energies = test_energies - mean_e\n",
    "\n",
    "test_forces = [structure.arrays[\"forces\"] for structure in test_structures]\n",
    "test_forces = np.concatenate(test_forces, axis = 0) * FORCE_FACTOR\n",
    "\n",
    "coef_der_test, central_indices_test, derivative_indices_test = \\\n",
    "get_coef_ders(test_structures, HYPERS, all_species)\n",
    "\n",
    "\n",
    "for key in coef_der_test.keys():\n",
    "    coef_der_test[key] = coef_der_test[key] / torch.sqrt(L2_mean)\n",
    "\n",
    "n_atoms_train = len(get_structural_indices(train_structures))\n",
    "np.random.seed(0)\n",
    "sparse_indices = np.random.permutation(n_atoms_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organized-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel(features, sparse_points):\n",
    "    features = features / torch.sqrt(torch.sum(features * features, dim = 1))[:, None]\n",
    "    #print(\"features: \", features.shape)\n",
    "    return torch.matmul(features, torch.transpose(sparse_points, 0, 1)) ** 2\n",
    "\n",
    "class KernelSingle(torch.nn.Module):\n",
    "    def __init__(self, clebsch, sparse_points):\n",
    "        super(KernelSingle, self).__init__()\n",
    "        self.clebsch_combining = ClebschCombining(clebsch, 0)\n",
    "        n_sparse = sparse_points.shape[0]\n",
    "        sparse_points = sparse_points / torch.sqrt(torch.sum(sparse_points * sparse_points, dim = 1))[:, None]\n",
    "        self.register_parameter('sparse_points', torch.nn.Parameter(sparse_points))\n",
    "        self.linear = torch.nn.Linear(n_sparse, 1, bias = False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        ps = self.clebsch_combining(X, X)['0'].squeeze()\n",
    "        kernel_values = get_kernel(ps, self.sparse_points)\n",
    "        return {'energies' : self.linear(kernel_values)}\n",
    "    \n",
    "def get_mae(first, second):\n",
    "    return np.mean(np.abs(first - second))\n",
    "\n",
    "def get_rmse(first, second):\n",
    "    return np.sqrt(np.mean((first - second) ** 2))\n",
    "\n",
    "def measure_performance_torch(model, device):\n",
    "    \n",
    "   \n",
    "        \n",
    "    test_struc_ind = get_structural_indices(test_structures)\n",
    "    times_energies = []\n",
    "    times_energies_from_sph = []\n",
    "    for _ in range(N_MEASUREMENTS):\n",
    "        begin = time.time()\n",
    "        test_coefficients = get_coefs(test_structures, HYPERS, all_species)\n",
    "        for key in test_coefficients.keys():\n",
    "            test_coefficients[key] = test_coefficients[key].to(device) / torch.sqrt(L2_mean)\n",
    "        test_struc_indices = get_structural_indices(test_structures)\n",
    "        begin_from_sph = time.time()\n",
    "        energies_predictions = model(test_coefficients, structural_indices = test_struc_ind)['energies']\n",
    "        times_energies_from_sph.append(time.time() - begin_from_sph)\n",
    "        times_energies.append(time.time() - begin)\n",
    "    \n",
    "    energies_predictions = energies_predictions.data.cpu().numpy()\n",
    "    mae_energies = get_mae(energies_predictions, test_energies)\n",
    "    rmse_energies = get_rmse(energies_predictions, test_energies)\n",
    "    \n",
    "    for key in test_coefficients.keys():\n",
    "        test_coefficients[key].requires_grad = True\n",
    "        \n",
    "    times_forces = []\n",
    "    times_forces_from_sph = []\n",
    "    for _ in range(N_MEASUREMENTS):\n",
    "        begin = time.time()\n",
    "        \n",
    "        test_coefficients = get_coefs(test_structures, HYPERS, all_species)\n",
    "        for key in test_coefficients.keys():\n",
    "            test_coefficients[key] = test_coefficients[key].to(device) / torch.sqrt(L2_mean)\n",
    "            test_coefficients[key].requires_grad = True\n",
    "        \n",
    "        test_struc_indices = get_structural_indices(test_structures)\n",
    "        \n",
    "        coef_der_test, central_indices_test, derivative_indices_test = \\\n",
    "        get_coef_ders(test_structures, HYPERS, all_species)\n",
    "        for key in coef_der_test.keys():\n",
    "            coef_der_test[key] = coef_der_test[key].to(device) / torch.sqrt(L2_mean)\n",
    "        begin_from_sph = time.time()\n",
    "        forces_predictions = model.get_forces(coef_der_test, central_indices_test, derivative_indices_test,\n",
    "                                              test_coefficients, structural_indices = test_struc_ind) \n",
    "        times_forces_from_sph.append(time.time() - begin_from_sph)                               \n",
    "        times_forces.append(time.time() - begin)\n",
    "        \n",
    "    forces_predictions = forces_predictions.data.cpu().numpy()\n",
    "    mae_forces = get_mae(forces_predictions, test_forces)\n",
    "    rmse_forces = get_rmse(forces_predictions, test_forces)\n",
    "    result = {'times_energies' : times_energies,\n",
    "              'times_energies_from_sph' : times_energies_from_sph,\n",
    "              'times_forces' : times_forces,\n",
    "              'times_forces_from_sph' : times_forces_from_sph,\n",
    "              'mae_energies' : mae_energies,\n",
    "              'rmse_energies' : rmse_energies,\n",
    "              'mae_forces' : mae_forces,\n",
    "              'rmse_forces' : rmse_forces}\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_skm_torch(n_sparse, device):\n",
    "    #print(device)\n",
    "   \n",
    "    \n",
    "    block = ClebschCombining(clebsch.precomputed_, 0)\n",
    "    train_ps = block(train_coefficients, train_coefficients)['0'].squeeze()\n",
    "    test_ps = block(test_coefficients, test_coefficients)['0'].squeeze()\n",
    "\n",
    "    \n",
    "    sparse_points = train_ps[sparse_indices[0:n_sparse]]\n",
    "\n",
    "    train_kernel = get_kernel(train_ps, sparse_points)\n",
    "    test_kernel = get_kernel(test_ps, sparse_points)\n",
    "    #print([0:5])\n",
    "   \n",
    "    accumulator = Accumulator()\n",
    "    \n",
    "    train_kernel = accumulator({\"kernel\": train_kernel}, get_structural_indices(train_structures))['kernel']\n",
    "    test_kernel = accumulator({\"kernel\": test_kernel}, get_structural_indices(test_structures))['kernel']\n",
    "    \n",
    "    #print(train_kernel[0:5])\n",
    "    regr = Ridge(alpha = 1e-10, fit_intercept = False)\n",
    "    regr.fit(train_kernel.data.cpu().numpy(), train_energies)\n",
    "    #print(regr.coef_.dtype)\n",
    "    block = KernelSingle(clebsch.precomputed_, sparse_points).to(device)\n",
    "    with torch.no_grad():\n",
    "        block.linear.weight = torch.nn.Parameter(torch.from_numpy(regr.coef_).\\\n",
    "                                                 type(torch.get_default_dtype()).to(device))\n",
    "    model = Atomistic(block).to(device)\n",
    "    model = model.train(False)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "annoying-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skm_rascal(n_sparse, destination):\n",
    "    hypers_ps = copy.deepcopy(HYPERS)\n",
    "    hypers_ps['soap_type'] = 'PowerSpectrum'\n",
    "    hypers_ps['normalize'] = True\n",
    "    if (destination == \"forces\") :\n",
    "        hypers_ps['compute_gradients'] = True\n",
    "    \n",
    "    soap = SphericalInvariants(**hypers_ps)\n",
    "    train_managers = soap.transform(train_structures)\n",
    "    \n",
    "    n_sparse = {1:int(n_sparse / 2), 6:int(n_sparse / 2)}\n",
    "    compressor = FPSFilter(soap, n_sparse, act_on='sample per species')\n",
    "    X_sparse = compressor.select_and_filter(train_managers)\n",
    "    \n",
    "    zeta = 2\n",
    "    kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse')\n",
    "    KNM = kernel(train_managers, X_sparse)\n",
    "    #KNM_down = kernel(train_managers, X_sparse)\n",
    "    #KNM = np.vstack([KNM, KNM_down])\n",
    "    model = train_gap_model(kernel, train_structures, KNM, X_sparse, train_energies, {1: 0.0, 6: 0.0}, \n",
    "                            lambdas = [1.0, 0.0], jitter=1e-13)\n",
    "    return model\n",
    "\n",
    "def measure_performance_rascal(model, task):\n",
    "    if task == \"energies\":\n",
    "        hypers_ps = copy.deepcopy(HYPERS)\n",
    "        hypers_ps['soap_type'] = 'PowerSpectrum'\n",
    "        hypers_ps['normalize'] = True\n",
    "        soap = SphericalInvariants(**hypers_ps)\n",
    "\n",
    "        times_energies = []\n",
    "        for _ in range(N_MEASUREMENTS):\n",
    "            begin = time.time()\n",
    "            managers_test = soap.transform(test_structures)\n",
    "            predictions_energies = model.predict(managers_test)\n",
    "            times_energies.append(time.time() - begin)\n",
    "        mae_energies = get_mae(predictions_energies, test_energies)\n",
    "        rmse_energies = get_rmse(predictions_energies, test_energies)\n",
    "        return {'mae_energies' : mae_energies,\n",
    "            'rmse_energies' : rmse_energies,\n",
    "            'times_energies' : times_energies}\n",
    "    \n",
    "    if task == \"forces\":\n",
    "        hypers_ps_grad = copy.deepcopy(HYPERS)\n",
    "        hypers_ps_grad['soap_type'] = 'PowerSpectrum'\n",
    "        hypers_ps_grad['normalize'] = True\n",
    "        hypers_ps_grad['compute_gradients'] = True\n",
    "        soap = SphericalInvariants(**hypers_ps_grad)\n",
    "\n",
    "        times_forces = []\n",
    "        for _ in range(N_MEASUREMENTS):\n",
    "            begin = time.time()\n",
    "            managers_test = soap.transform(test_structures)\n",
    "            predictions_forces = model.predict_forces(managers_test)\n",
    "            times_forces.append(time.time() - begin)\n",
    "        mae_forces = get_mae(predictions_forces, test_forces)\n",
    "        rmse_forces = get_rmse(predictions_forces, test_forces)\n",
    "        return { 'mae_forces' : mae_forces,\n",
    "                'rmse_forces' : rmse_forces,\n",
    "                'times_forces' : times_forces}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collect-photograph",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pseudo points selected by central atom species is: {1: 5, 6: 5}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 12, 6: 12}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 25, 6: 25}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 50, 6: 50}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 125, 6: 125}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 250, 6: 250}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 500, 6: 500}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 1250, 6: 1250}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 2500, 6: 2500}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "The number of pseudo points selected by central atom species is: {1: 5000, 6: 5000}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "rascal_E_times = []\n",
    "for n_sparse in GRID:\n",
    "    model = get_skm_rascal(n_sparse, \"energies\")\n",
    "    statistics = measure_performance_rascal(model, \"energies\")\n",
    "    rascal_E_times.append(np.mean(statistics[\"times_energies\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "rascal_F_times = []\n",
    "for n_sparse in GRID:\n",
    "    model = get_skm_rascal(n_sparse, \"forces\")\n",
    "    statistics = measure_performance_rascal(model, \"forces\")\n",
    "    rascal_F_times.append(np.mean(statistics[\"times_forces\"]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch_cpu_E_times = []\n",
    "torch_cpu_F_times = []\n",
    "torch_cpu_E_times_from_sph = []\n",
    "torch_cpu_F_times_from_sph = []\n",
    "for n_sparse in tqdm.tqdm(GRID):\n",
    "    model = get_skm_torch(n_sparse, 'cpu')\n",
    "    statistics = measure_performance_torch(model, 'cpu')\n",
    "    torch_cpu_E_times.append(np.mean(statistics[\"times_energies\"]))\n",
    "    torch_cpu_F_times.append(np.mean(statistics[\"times_forces\"]))\n",
    "    torch_cpu_E_times_from_sph.append(np.mean(statistics[\"times_energies_from_sph\"]))\n",
    "    torch_cpu_F_times_from_sph.append(np.mean(statistics[\"times_forces_from_sph\"]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch_cuda_E_times = []\n",
    "torch_cuda_F_times = []\n",
    "torch_cuda_E_times_from_sph = []\n",
    "torch_cuda_F_times_from_sph = []\n",
    "for n_sparse in tqdm.tqdm(GRID):\n",
    "    model = get_skm_torch(n_sparse, 'cuda')\n",
    "    model = model.cuda()\n",
    "    statistics = measure_performance_torch(model, 'cuda')\n",
    "    torch_cuda_E_times.append(np.mean(statistics[\"times_energies\"]))\n",
    "    torch_cuda_F_times.append(np.mean(statistics[\"times_forces\"]))\n",
    "    torch_cuda_E_times_from_sph.append(np.mean(statistics[\"times_energies_from_sph\"]))\n",
    "    torch_cuda_F_times_from_sph.append(np.mean(statistics[\"times_forces_from_sph\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(GRID, torch_cpu_E_times, label = 'torch cpu total')\n",
    "plt.plot(GRID, torch_cuda_E_times, label = 'torch gpu total')\n",
    "plt.plot(GRID, torch_cpu_E_times_from_sph, label = 'torch cpu from sph')\n",
    "plt.plot(GRID, torch_cuda_E_times_from_sph, label = 'torch gpu from sph')\n",
    "\n",
    "plt.plot(GRID, rascal_E_times, label = 'rascal cpu')\n",
    "plt.xlabel(\"N sparse\")\n",
    "plt.ylabel(\"time\")\n",
    "plt.xscale('log')\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Energies\")\n",
    "plt.legend()\n",
    "plt.savefig(\"energies_big_bench_torch.float64.pdf\", dpi = 200, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(GRID, torch_cpu_F_times, label = 'torch cpu total')\n",
    "plt.plot(GRID, torch_cuda_F_times, label = 'torch gpu total')\n",
    "plt.plot(GRID, torch_cpu_F_times_from_sph, label = 'torch cpu from sph')\n",
    "plt.plot(GRID, torch_cuda_F_times_from_sph, label = 'torch gpu from sph')\n",
    "plt.plot(GRID, rascal_F_times, label = 'rascal cpu')\n",
    "plt.xlabel(\"N sparse\")\n",
    "plt.ylabel(\"time\")\n",
    "plt.xscale('log')\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Forces\")\n",
    "plt.legend()\n",
    "plt.savefig(\"forces_big_bench_torch.float64.pdf\", dpi = 200, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-pasta",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
