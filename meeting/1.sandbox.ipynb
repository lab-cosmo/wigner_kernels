{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from code_pytorch import *\n",
    "from utilities import *\n",
    "from miscellaneous import ClebschGordan\n",
    "import ase.io\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adequate-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_MAX = 3\n",
    "HYPERS = {\n",
    "    'interaction_cutoff': 6.3,\n",
    "    'max_radial': 5,\n",
    "    'max_angular': LAMBDA_MAX,\n",
    "    'gaussian_sigma_type': 'Constant',\n",
    "    'gaussian_sigma_constant': 0.05,\n",
    "    'cutoff_smooth_width': 0.3,\n",
    "    'radial_basis': 'GTO'\n",
    "    \n",
    "}\n",
    "subset = '0:100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advance-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = ase.io.read('../methane.extxyz' , index=subset)\n",
    "all_species = get_all_species(structures)\n",
    "coefficients = get_coefs(structures, HYPERS, all_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-tension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500, 10, 1])\n",
      "1 torch.Size([500, 10, 3])\n",
      "2 torch.Size([500, 10, 5])\n",
      "3 torch.Size([500, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "for key in coefficients.keys():\n",
    "    print(key, coefficients[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharp-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = copy.deepcopy(coefficients)\n",
    "all_features['bla bla bla'] = torch.randn(500, 137)\n",
    "all_features['one another'] = torch.randn(500, 42, 42, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italian-vacation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500, 10, 1])\n",
      "1 torch.Size([500, 10, 3])\n",
      "2 torch.Size([500, 10, 5])\n",
      "3 torch.Size([500, 10, 7])\n",
      "bla bla bla torch.Size([500, 137])\n",
      "one another torch.Size([500, 42, 42, 42])\n"
     ]
    }
   ],
   "source": [
    "for key in all_features.keys():\n",
    "    print(key, all_features[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dense-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = CentralSplitter()\n",
    "splitted = block(all_features, get_central_species(structures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "responsible-acting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 torch.Size([400, 10, 1])\n",
      "1 1 torch.Size([400, 10, 3])\n",
      "1 2 torch.Size([400, 10, 5])\n",
      "1 3 torch.Size([400, 10, 7])\n",
      "1 bla bla bla torch.Size([400, 137])\n",
      "1 one another torch.Size([400, 42, 42, 42])\n",
      "6 0 torch.Size([100, 10, 1])\n",
      "6 1 torch.Size([100, 10, 3])\n",
      "6 2 torch.Size([100, 10, 5])\n",
      "6 3 torch.Size([100, 10, 7])\n",
      "6 bla bla bla torch.Size([100, 137])\n",
      "6 one another torch.Size([100, 42, 42, 42])\n"
     ]
    }
   ],
   "source": [
    "for key1 in splitted.keys():\n",
    "    for key2 in splitted[key1].keys():\n",
    "        print(key1, key2, splitted[key1][key2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fresh-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500, 10, 1])\n",
      "1 torch.Size([500, 10, 3])\n",
      "2 torch.Size([500, 10, 5])\n",
      "3 torch.Size([500, 10, 7])\n",
      "bla bla bla torch.Size([500, 137])\n",
      "one another torch.Size([500, 42, 42, 42])\n"
     ]
    }
   ],
   "source": [
    "block = CentralUniter()\n",
    "back = block(splitted, get_central_species(structures))\n",
    "for key in back.keys():\n",
    "    print(key, back[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incorporated-mercury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([100, 10, 1])\n",
      "1 torch.Size([100, 10, 3])\n",
      "2 torch.Size([100, 10, 5])\n",
      "3 torch.Size([100, 10, 7])\n",
      "bla bla bla torch.Size([100, 137])\n",
      "one another torch.Size([100, 42, 42, 42])\n"
     ]
    }
   ],
   "source": [
    "block = Accumulator()\n",
    "summed = block(back, get_structural_indices(structures))\n",
    "for key in summed.keys():\n",
    "    print(key, summed[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wrapped-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500, 400, 1])\n",
      "1 torch.Size([500, 900, 3])\n",
      "2 torch.Size([500, 1100, 5])\n",
      "3 torch.Size([500, 1000, 7])\n",
      "4 torch.Size([500, 600, 9])\n",
      "5 torch.Size([500, 300, 11])\n",
      "6 torch.Size([500, 100, 13])\n"
     ]
    }
   ],
   "source": [
    "block = ClebschCombining(ClebschGordan(2 * LAMBDA_MAX).precomputed_, 2 * LAMBDA_MAX)\n",
    "ps_covariants = block(coefficients, coefficients)\n",
    "for key in ps_covariants.keys():\n",
    "    print(key, ps_covariants[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amended-commercial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([500, 400, 1])\n",
      "1 torch.Size([500, 900, 3])\n",
      "2 torch.Size([500, 1100, 5])\n"
     ]
    }
   ],
   "source": [
    "block = ClebschCombining(ClebschGordan(LAMBDA_MAX).precomputed_, 2)\n",
    "ps_covariants = block(coefficients, coefficients)\n",
    "for key in ps_covariants.keys():\n",
    "    print(key, ps_covariants[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-priority",
   "metadata": {},
   "source": [
    "## main block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "complex-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atomistic(torch.nn.Module):\n",
    "    def __init__(self, models, accumulate = True):\n",
    "        super(Atomistic, self).__init__()\n",
    "        self.accumulate = accumulate\n",
    "        if type(models) == dict:\n",
    "            self.central_specific = True\n",
    "            self.splitter = CentralSplitter()\n",
    "            self.uniter = CentralUniter()\n",
    "            self.models = nn.ModuleDict(models)\n",
    "        else:\n",
    "            self.central_specific = False\n",
    "            self.model = models\n",
    "        \n",
    "        \n",
    "        if self.accumulate:\n",
    "            self.accumulator = Accumulator()\n",
    "        \n",
    "    def forward(self, X, central_species = None, structural_indices = None):\n",
    "        if self.central_specific:\n",
    "            if central_species is None:\n",
    "                raise ValueError(\"central species should be provided for central specie specific model\")\n",
    "                      \n",
    "\n",
    "            splitted = self.splitter(X, central_species)\n",
    "            result = {}\n",
    "            for key in splitted.keys():            \n",
    "                result[key] = self.models[str(key)](splitted[key])\n",
    "            result = self.uniter(result, central_species)\n",
    "        else:\n",
    "            result = self.model(X)\n",
    "            \n",
    "        if self.accumulate:\n",
    "            if structural_indices is None:\n",
    "                raise ValueError(\"structural indices should be provided to accumulate structural targets\")\n",
    "            result = self.accumulator(result, structural_indices)\n",
    "        return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
